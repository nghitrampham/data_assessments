{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1dd809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### basic package for data science project\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "import helpers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee64aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c26e0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86079e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = IterativeImputer(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a626de6d",
   "metadata": {},
   "source": [
    "1. Remove columns with missing value more than 75% \n",
    "2. Remove col 'x39' and 'x99' since those two columns don't bring additional information \n",
    "3. Impute NAN for missing values in numerical methods \n",
    "4. We can use Catboost or Imputing categorical features is to replace missing values with the most common class. \n",
    "\n",
    "\n",
    "Alternative (if time permitted):\n",
    "    - Check each features to see if there exists outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a23dea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/exercise_40_train.csv')\n",
    "test_data = pd.read_csv('data/exercise_40_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2195e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_missing_cols = list(set(train_data.columns[train_data.isnull().mean() > 0.4]))\n",
    "remove_cat_col = ['x39', 'x99']\n",
    "remove_cols = most_missing_cols + remove_cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "38c2c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_df(df, cat_cols, dummy_na):\n",
    "    for col in  cat_cols:\n",
    "        try:\n",
    "            # for each cat add dummy var, drop original column\n",
    "            df = pd.concat([df.drop(col, axis=1),\\\n",
    "                            pd.get_dummies(df[col], prefix=col, prefix_sep='_', drop_first=True, dummy_na=dummy_na)], axis=1)\n",
    "        except:\n",
    "            continue\n",
    "    return df\n",
    "\n",
    "def clean_catergorical_ft(df):\n",
    "    \n",
    "    cat_df = df.select_dtypes(include=['object'])\n",
    "    \n",
    "    #### clean col x7 and x19\n",
    "    cat_df['x7'] = cat_df['x7'].str.replace('%','')\n",
    "    cat_df[\"x19\"] = cat_df['x19'].str.replace('$','')\n",
    "    cat_df = cat_df.astype({'x7': 'float', 'x19': 'float'})\n",
    "\n",
    "    #### clean x3 col\n",
    "    cat_df['x3'] = cat_df.apply(lambda x: helpers.clean_day_x3_col(x['x3']), axis = 1)\n",
    "\n",
    "    ### convert x7 and x19 back to numerical fts \n",
    "    df['x7'] =  cat_df['x7']\n",
    "    df['x19'] = cat_df[\"x19\"]\n",
    "\n",
    "    #### categorical cols \n",
    "    cat_df.drop(['x7','x19'], axis = 1, inplace = True)\n",
    "    cat_cols = cat_df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    return cat_cols, cat_df, df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ea88b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2ae2842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_engineering(df, remove_cols, data_type = \"train\", label_encoder_path = \"le_dict.pickle\", use_catboost = True):\n",
    "    df = train_data.copy()\n",
    "    df = df.loc[:, (~df.columns.isin(remove_cols))]\n",
    "    print(df.shape)\n",
    "    #### clean categorical features\n",
    "    cat_cols, cat_df, df = clean_catergorical_ft(df)\n",
    "    \n",
    "    #### clean numerical features \n",
    "    numerical_df = df.loc[:, (~df.columns.isin(cat_cols))]\n",
    "\n",
    "    ### imputing missing values \n",
    "#     num_df_trasformed = pd.DataFrame(imp_mean.fit_transform(numerical_df.loc[:, ~(numerical_df.columns.isin([\"y\"]))]))\n",
    "    null_cols = list(set(numerical_df.columns[numerical_df.isnull().mean()!=0]))\n",
    "    for col in null_cols:\n",
    "        mean_freq = numerical_df[col].median()\n",
    "        numerical_df[col][pd.isna(numerical_df[col])] = mean_freq\n",
    "        \n",
    "    num_df_trasformed = numerical_df\n",
    "    ### if not using catboost model, then imputing categorical features \n",
    "    ### by replacing missing values with the most common class\n",
    "    ### use label encoder for col 'x33' and one-hot encoder for the rest\n",
    "    if use_catboost == False:\n",
    "        \n",
    "        ### replace missing value with most common value\n",
    "        for col in cat_cols:\n",
    "            max_freq = cat_df[col].value_counts().index[0]\n",
    "            cat_df[col][pd.isna(cat_df[col])] = max_freq\n",
    "    \n",
    "        one_hot_cols = cat_df.columns[cat_df.columns != 'x33']  \n",
    "        cat_df_transformed = create_dummy_df(cat_df, list(one_hot_cols), dummy_na= False)\n",
    "\n",
    "        if data_type == \"train\":\n",
    "            ### user label encoder for col 'x33'\n",
    "            le = LabelEncoder()\n",
    "            cat_df_transformed['x33'] = le.fit_transform(cat_df_transformed['x33'])\n",
    "\n",
    "            ### save labelEncoder for test set\n",
    "            with open(label_encoder_path, 'wb') as l:\n",
    "                pickle.dump(le, l, pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "        else: \n",
    "            with open(label_encoder_path, 'rb') as f:\n",
    "                le = pickle.load(f)\n",
    "            cat_df_transformed = le.transform(cat_df_transformed['x33'])\n",
    "    else:\n",
    "        cat_df_transformed = cat_df\n",
    "        cat_df_transformed = cat_df_transformed.fillna('NaN')\n",
    "    \n",
    "    cleaned_data = pd.concat([num_df_trasformed, cat_df_transformed], axis = 1)\n",
    "    cleaned_data[\"y\"] = df['y']\n",
    "\n",
    "    return cleaned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "84687c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 94)\n"
     ]
    }
   ],
   "source": [
    "data = ft_engineering(df, remove_cols, data_type = \"train\", label_encoder_path = \"le_dict.pickle\", use_catboost = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0fa051d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x65_farmers</th>\n",
       "      <th>x65_geico</th>\n",
       "      <th>x65_progressive</th>\n",
       "      <th>x77_chevrolet</th>\n",
       "      <th>x77_ford</th>\n",
       "      <th>x77_mercedes</th>\n",
       "      <th>x77_nissan</th>\n",
       "      <th>x77_subaru</th>\n",
       "      <th>x77_toyota</th>\n",
       "      <th>x93_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.165254</td>\n",
       "      <td>18.060003</td>\n",
       "      <td>1.077380</td>\n",
       "      <td>-1.339233</td>\n",
       "      <td>-1.584341</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.220784</td>\n",
       "      <td>1.816481</td>\n",
       "      <td>1.171788</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.441471</td>\n",
       "      <td>18.416307</td>\n",
       "      <td>1.482586</td>\n",
       "      <td>0.920817</td>\n",
       "      <td>-0.759931</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>1.192441</td>\n",
       "      <td>3.513950</td>\n",
       "      <td>1.419900</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4.427278</td>\n",
       "      <td>19.188092</td>\n",
       "      <td>0.145652</td>\n",
       "      <td>0.366093</td>\n",
       "      <td>0.709962</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.952323</td>\n",
       "      <td>0.782974</td>\n",
       "      <td>-1.247022</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.925235</td>\n",
       "      <td>19.901257</td>\n",
       "      <td>1.763602</td>\n",
       "      <td>-0.251926</td>\n",
       "      <td>-0.827461</td>\n",
       "      <td>-0.0057</td>\n",
       "      <td>-0.520756</td>\n",
       "      <td>1.825586</td>\n",
       "      <td>2.223038</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.868802</td>\n",
       "      <td>22.202473</td>\n",
       "      <td>3.405119</td>\n",
       "      <td>0.083162</td>\n",
       "      <td>1.381504</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>-0.732739</td>\n",
       "      <td>2.151990</td>\n",
       "      <td>-0.275406</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y        x1         x2        x4        x5        x6      x7        x8  \\\n",
       "0  0  0.165254  18.060003  1.077380 -1.339233 -1.584341  0.0062  0.220784   \n",
       "1  1  2.441471  18.416307  1.482586  0.920817 -0.759931  0.0064  1.192441   \n",
       "2  1  4.427278  19.188092  0.145652  0.366093  0.709962 -0.0008  0.952323   \n",
       "3  0  3.925235  19.901257  1.763602 -0.251926 -0.827461 -0.0057 -0.520756   \n",
       "4  0  2.868802  22.202473  3.405119  0.083162  1.381504  0.0109 -0.732739   \n",
       "\n",
       "         x9       x10  ...  x65_farmers  x65_geico  x65_progressive  \\\n",
       "0  1.816481  1.171788  ...            1          0                0   \n",
       "1  3.513950  1.419900  ...            0          0                0   \n",
       "2  0.782974 -1.247022  ...            0          1                0   \n",
       "3  1.825586  2.223038  ...            0          1                0   \n",
       "4  2.151990 -0.275406  ...            0          1                0   \n",
       "\n",
       "   x77_chevrolet  x77_ford  x77_mercedes  x77_nissan  x77_subaru  x77_toyota  \\\n",
       "0              0         0             1           0           0           0   \n",
       "1              0         0             1           0           0           0   \n",
       "2              0         0             0           0           1           0   \n",
       "3              0         0             0           1           0           0   \n",
       "4              0         0             0           0           0           1   \n",
       "\n",
       "   x93_yes  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "90200242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data.columns[data.isnull().mean()!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "82bc4297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    data.drop(['y'], axis=1),\n",
    "                                    data['y'],\n",
    "                                    test_size=0.15,\n",
    "                                    random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd54a2bb",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a64055fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, auc, precision_recall_curve, roc_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "482a9347",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, C = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "312f2fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85602941, 0.85617647, 0.85617647, 0.85632353, 0.85617647])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d3f95eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.2, random_state=0)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d7edc906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6065128322500647\n",
      "Accuracy:  0.8476666666666667\n"
     ]
    }
   ],
   "source": [
    "#Generate predicted probabilites\n",
    "clf_probs = clf.predict_proba(X_test)\n",
    "print('AUC: ', roc_auc_score(y_test, clf_probs[:,1]))\n",
    "print('Accuracy: ', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f90aa2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC score:       0.6065\n",
      "Best threshold       0.1500\n",
      "\n",
      "Confusion Matrix : \n",
      " [[3278 1809]\n",
      " [ 442  471]]\n",
      "\n",
      "=============\n",
      "Accuracy    :       0.6248\n",
      "Sensitivity :       0.6444\n",
      "Specificity :       0.5159\n"
     ]
    }
   ],
   "source": [
    "reporting(clf.predict_proba(X_test)[:,1], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a2b1d902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=3, estimator=LogisticRegression(), n_jobs=-1, scoring='roc_auc',\n",
       "      step=5)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "score = 'roc_auc'\n",
    "#Setup recursive feature reduction w/ cross validation\n",
    "clf2 = RFECV(LogisticRegression(),\n",
    "      scoring = score,\n",
    "      n_jobs = -1,\n",
    "      cv = 3,\n",
    "      step = 5)\n",
    "clf2.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e9f32131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6947079200875199\n",
      "Accuracy:  0.8478333333333333\n"
     ]
    }
   ],
   "source": [
    "#Generate predicted probabilites\n",
    "clf2_probs = clf2.predict_proba(X_test)\n",
    "print('AUC: ', roc_auc_score(y_test, clf2_probs[:,1]))\n",
    "print('Accuracy: ', clf2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41de227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "16d35b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporting(ensem_preds, targets):\n",
    "    best_th = 0\n",
    "    best_score = 0\n",
    "\n",
    "    for th in np.arange(0.0, 0.6, 0.01):\n",
    "        pred = (ensem_preds > th).astype(int)\n",
    "        score = f1_score(targets, pred)\n",
    "        if score > best_score:\n",
    "            best_th = th\n",
    "            best_score = score\n",
    "\n",
    "    print(f\"\\nAUC score: {roc_auc_score(targets, ensem_preds):12.4f}\")\n",
    "    print(f\"Best threshold {best_th:12.4f}\")\n",
    "\n",
    "    preds = (ensem_preds > best_th).astype(int)\n",
    "    # print(classification_report(targets, preds, digits=3))\n",
    "\n",
    "    cm1 = confusion_matrix(targets, preds)\n",
    "    print('\\nConfusion Matrix : \\n', cm1)\n",
    "    total1=sum(sum(cm1))\n",
    "\n",
    "    print('\\n=============')\n",
    "    accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
    "    print (f'Accuracy    : {accuracy1:12.4f}')\n",
    "\n",
    "    sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    print(f'Sensitivity : {sensitivity1:12.4f}')\n",
    "\n",
    "    specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    print(f'Specificity : {specificity1:12.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf388e6",
   "metadata": {},
   "source": [
    "### Removing features using lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1e816e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=0.1, penalty='l1',\n",
       "                                             solver='saga'))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_ = SelectFromModel(LogisticRegression(penalty='l1', solver='saga', C = 0.1))\n",
    "sel_.fit(scaler.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6ba606c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 116\n",
      "selected features: 100\n",
      "features with coefficients shrank to zero: 15\n"
     ]
    }
   ],
   "source": [
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "      np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "df5d73c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x22', 'x26', 'x48', 'x59', 'x69', 'x72', 'x79', 'x81', 'x88', 'x90',\n",
       "       'x24_male', 'x60_January', 'x65_esurance', 'x77_chevrolet', 'x77_ford'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "removed_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9547487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = sel_.transform(X_train)\n",
    "X_test_selected = sel_.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "358c5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_selected = LogisticRegression(random_state=0, C = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "90b1b268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85602941, 0.85617647, 0.85617647, 0.85632353, 0.85617647])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf_selected, X_train, y_train, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b83b6568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.2, random_state=0)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_selected.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ed1ae120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6067447228734801\n",
      "Accuracy:  0.8476666666666667\n"
     ]
    }
   ],
   "source": [
    "#Generate predicted probabilites\n",
    "clf_probs = clf_selected.predict_proba(X_test_selected)\n",
    "print('AUC: ', roc_auc_score(y_test, clf_probs[:,1]))\n",
    "print('Accuracy: ', clf_selected.score(X_test_selected, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b466c504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC score:       0.6067\n",
      "Best threshold       0.1500\n",
      "\n",
      "Confusion Matrix : \n",
      " [[3222 1865]\n",
      " [ 434  479]]\n",
      "\n",
      "=============\n",
      "Accuracy    :       0.6168\n",
      "Sensitivity :       0.6334\n",
      "Specificity :       0.5246\n"
     ]
    }
   ],
   "source": [
    "reporting(clf_selected.predict_proba(X_test_selected)[:,1], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840839f3",
   "metadata": {},
   "source": [
    "## Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f599c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
